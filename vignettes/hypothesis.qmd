---
title: Hypothesis Tests
---


```{r, include = FALSE}
options(width = 1000)
# this vignette is in .Rbuildignore because lme4 is not available on old CRAN
# test machines.

knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 9,
  fig.asp = .4,
  out.width = "100%",
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)
options(marginaleffects_print_style = "tinytable")
options("tinytable_theme_placement_latex_float" = "H")
```
```{css, echo=FALSE}
.table {
  font-size: .8em;
}
.table td, .table th {
  white-space: nowrap;
}
```

The `marginaleffects` package can conduct linear or non-linear hypothesis tests on the coefficients of any supported model class, or on the quantities generated by any of the other functions of the package: `predictions()`, `comparisons()`, or `slopes()`.

There are two main entry points for hypothesis tests:

1. `marginaleffects` functions: Use the `hypothesis` argument.
2. Other `R` objects and models: Use the `hypotheses()` function.

Both the `hypothesis` argument and the `hypotheses()` function accept several input types, which allow a lot of flexibility in the specification of hypothesis tests:

1. Numeric: Value of a null hypothesis.
2. Formula: Equation of a (non-)linear hypothesis test.
3. Function: Tests on arbitrary transformations or aggregations.
4. Matrix: Contrast matrices and vectors.

This vignette shows how to use each of these strategies to conduct hypothesis tests on model coefficients or on the quantities estimated by the `marginaleffects` package. After reading it, you will be able to specify custom hypothesis tests and contrasts to assess statements like:

* The coefficients $\beta_1$ and $\beta_2$ are equal.
* The slope of $Y$ with respect to $X_1$ is equal to the slope with respect to $X_2$. 
* The average treatment effect of $X$ when $W=0$ is equal to the average treatment effect of $X$ when $W=1$.
* A non-linear function of predicted values is equal to 100.
* The marginal mean in the control group is equal to the average of marginal means in the other 3 treatment arms.
* Cross-level contrasts: In a multinomial model, the effect of $X$ on the 1st outcome level is equal to the effect of $X$ on the 2nd outcome level.


# Numeric (null hypothesis)

The simplest way to modify a hypothesis test is to change the null hypothesis. By default, all functions in the `marginaleffects` package assume that the null is 0. This can be changed with the `hypothesis` argument. 


## Coefficients

Consider a simple logistic regression model:

```{r}
library(marginaleffects)
mod <- glm(am ~ hp + drat, data = mtcars, family = binomial)
```

By default, the `summary()` function will report the results of hypothesis tests where the null is set to 0:

```{r}
summary(mod)
```

Using `hypotheses()`, we can easily change the null hypothesis:

```{r}
hypotheses(mod, hypothesis = 6)
```

## Predictions

Changing the value of the null is particularly important in the context of predictions, where the 0 baseline may not be particularly meaningful. For example, here we compute the predicted outcome for a hypothetical unit where all regressors are fixed to their sample means:

```{r}
predictions(mod, newdata = "mean")
```

The Z statistic and p value reported above assume that the null hypothesis equals zero. We can change the null with the `hypothesis` argument:

```{r}
predictions(mod, newdata = "mean", hypothesis = .5)
```

## Comparisons and slopes

When computing different quantities of interest like risk ratios, it can make sense to set the null hypothesis to 1 rather than 0:

```{r}
avg_comparisons(
    mod,
    variables = "hp",
    comparison = "ratio",
    hypothesis = 1) |>
    print(digits = 5)
```


# Equations

The `hypotheses()` function emulates the equation-based syntax of the well-established `car::deltaMethod` and `car::linearHypothesis` functions. However, `marginaleffects` supports more models, requires fewer dependencies, and offers some convenience features like the  `vcov` argument for robust standard errors.

The syntax we illustrate in this section takes the form a string equation, ex: `"am = 2 * vs"`


## Coefficients

Let's start by estimating a simple model:

```{r}
library(marginaleffects)
mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)
```

When the `FUN` and `hypothesis` arguments of `hypotheses()` equal `NULL` (the default), the function returns a data.frame of raw estimates:

```{r}
hypotheses(mod)
```

Test of equality between coefficients:

```{r}
hypotheses(mod, "hp = wt")
```

Non-linear function of coefficients

```{r}
hypotheses(mod, "exp(hp + wt) = 0.1")
```

The `vcov` argument behaves in the same was as in all the other  `marginaleffects` functions, allowing us to easily compute robust standard errors:

```{r}
hypotheses(mod, "hp = wt", vcov = "HC3")
```

We can use shortcuts like `b1`, `b2`, `...` to identify the position of each parameter in the output of `FUN`. For example, `b2=b3` is equivalent to `hp=wt` because those term names appear in the 2nd and 3rd row when we call `hypotheses(mod)`.

```{r}
hypotheses(mod, "b2 = b3")
```

```{r}
hypotheses(mod, hypothesis = "b* / b3 = 1")
```

Term names with special characters must be enclosed in backticks:

```{r}
hypotheses(mod, "`factor(cyl)6` = `factor(cyl)8`")
```

## Predictions

Now consider the case of adjusted predictions:

```{r}
mod <- lm(mpg ~ am + vs, data = mtcars)

p <- predictions(
    mod,
    newdata = datagrid(am = 0:1, vs = 0:1))
p
```

Since there is no `term` column in the output of the `predictions` function, we must use parameter identifiers like `b1`, `b2`, etc. to determine which estimates we want to compare:

```{r}
hypotheses(p, hypothesis = "b1 = b2")
```

Or directly:

```{r}
predictions(
    mod,
    hypothesis = "b1 = b2",
    newdata = datagrid(am = 0:1, vs = 0:1))

p$estimate[1] - p$estimate[2]
```
There are *many* more possibilities:

```{r}
predictions(
    mod,
    hypothesis = "b1 + b2 = 30",
    newdata = datagrid(am = 0:1, vs = 0:1))

p$estimate[1] + p$estimate[2] - 30

predictions(
    mod,
    hypothesis = "(b2 - b1) / (b3 - b2) = 0",
    newdata = datagrid(am = 0:1, vs = 0:1))
```

## Comparisons and slopes

The `avg_comparisons()` function allows us to answer questions of this form: On average, how does the expected outcome change when I change one regressor by some amount? Consider this:

```{r}
mod <- lm(mpg ~ am + vs, data = mtcars)

cmp <- avg_comparisons(mod)
cmp
```

This tells us that, on average, moving from 0 to 1 on the `am` changes the predicted outcome by about `r round(cmp$estimate[1], 1)`, and changing .`vs` from 0 to 1 changes the predicted outcome by about `r round(cmp$estimate[2], 1)`. 

Is the difference between those two estimates statistically significant? In other words, Is the effect of `am` equal to the effect of `vs`? To answer this question, we use the `hypothesis` argument:

```{r}
avg_comparisons(mod, hypothesis = "am = vs")
```

The `hypothesis` string can include any valid `R` expression, so we can run some silly non-linear tests:

```{r}
avg_comparisons(mod, hypothesis = "exp(am) - 2 * vs = -400")
```

Note that the p values and confidence intervals are calculated using the delta method and are thus based on the assumption that the `hypotheses` expression is approximately normally distributed. For (very) non-linear functions of the parameters, this is not realistic, and we get p values with incorrect error rates and confidence intervals with incorrect coverage probabilities. For such hypotheses, it’s better to calculate the confidence intervals using the bootstrap (see [`inferences`](reference/inferences.html) for details):

While the confidence interval from the delta method is symmetric, equal to the estimate ± 1.96 times the standard error, the (perhaps) more reliable confidence interval from the bootstrap is highly skewed.

```{r}
#| cache: true
set.seed(1234)

avg_comparisons(mod, hypothesis = "exp(am) - 2 * vs = -400") |>
  inferences(method = "boot")
```

The same approach can be taken to compare slopes:

```{r}
mod <- lm(mpg ~ qsec * hp, data = mtcars)

avg_slopes(mod, hypothesis = "10 * hp - qsec = 0")
```


# Formulas (Group-wise)

Since version 0.20.1.5 of `marginaleffects`, the `hypothesis` argument also accepts a formula to specify hypotheses to be tested on every row of the output, or within subsets. Consider this set of average predictions:

```{r}
dat <- within(mtcars, {
    gear = factor(gear)
    cyl = factor(cyl)
})
dat <- sort_by(dat, ~ gear + cyl + am)
mod <- lm(mpg ~ am * wt * factor(cyl), data = dat)

avg_predictions(mod, by = "gear")
```

We can make "sequential", "reference", or "meandev" comparisons, either as differences (the default) or ratios:

```{r}
avg_predictions(mod, 
    hypothesis = ~ sequential,
    by = "gear")

avg_predictions(mod, 
    hypothesis = ~ meandev,
    by = "gear")

avg_predictions(mod, 
    hypothesis = ratio ~ sequential,
    by = "gear")
```


We can also test hypotheses by subgroup. For example, in this case, we want to compare every estimate to the reference category (first estimate) in each subset of `am`:

```{r}
avg_predictions(mod, 
    by = c("am", "gear")
)

avg_predictions(mod, 
    hypothesis = ~ sequential | am,
    by = c("am", "gear")
)
```

The grouping component of the formula is particularly useful when conducting tests on contrasts:

```{r}
avg_comparisons(mod, 
    variables = "cyl",
    by = "am")

avg_comparisons(mod, 
    variables = "cyl",
    by = "am", 
    hypothesis = ~ sequential | contrast)

avg_comparisons(mod, 
    variables = "cyl",
    by = "am", 
    hypothesis = ~ sequential | am)
```

It is also a powerful tool in categorical outcome models, to compare estimates for different outcome levels:

```{r}
library("MASS")

mod <- polr(gear ~ cyl + hp, dat)

avg_comparisons(mod, variables = "cyl")
```

Is the "8 vs. 4" contrast equal to the "6 vs. 4" contrast, within each outcome level?

```{r}
avg_comparisons(mod, 
    variables = "cyl",
    hypothesis = ~ sequential | group)
```

Is the "8 vs. 4" contrast for outcome level 3 equal to the "8 vs. 4" contrast for outcome level 4?

```{r}
avg_comparisons(mod, 
    variables = "cyl",
    hypothesis = ~ sequential | contrast)
```

# Functions

Hypothesis tests can also be conducted using arbitrary `R` functions. This allows users to test hypotheses on complex aggregations or transformations. To achieve this, we define a custom function which accepts a fitted model or `marginaleffects` objects, and returns a data frame with at least two columns: `term` (or `hypothesis`) and `estimate`.


## Predictions

When supplying a function to the `hypothesis` argument, that function must accept an argument `x` which is a data frame with columns `rowid` and `estimate` (and optional columns for other elements of `newdata`). That function must return a data frame with columns `term` (or `hypothesis`) and `estimate`.

In this example, we test if the mean predicted value is different from 2:


```{r}
dat <- transform(mtcars, gear = factor(gear), cyl = factor(cyl))

mod <- lm(wt ~ mpg * hp * cyl, data = dat)

hyp <- function(x) {
    data.frame(
        hypothesis = "Avg(Ŷ) = 2",
        estimate = mean(x$estimate) - 2
    )
}
predictions(mod, hypothesis = hyp)
```

In this ordinal logit model, the `predictions()` function returns one row per observation and per level of the outcome variable:

```{r}
#| messages: false
library(MASS)
library(dplyr)

mod <- polr(gear ~ cyl + hp, dat)

avg_predictions(mod)
```

We can use a function in the `hypothesis` argument to collapse the rows, displaying the average predicted values in groups 3-4 vs. 5:

```{r}
fun <- function(x) {
    out <- x |> 
        mutate(term = ifelse(group %in% 3:4, "3 & 4", "5")) |>
        summarize(estimate = mean(estimate), .by = term)
    return(out)
}
avg_predictions(mod, hypothesis = fun)
```

And we can compare the two categories by doing:

```{r}
fun <- function(x) {
    out <- x |> 
        mutate(term = ifelse(group %in% 3:4, "3 & 4", "5")) |>
        summarize(estimate = mean(estimate), .by = term) |>
        summarize(estimate = diff(estimate), term = "5 - (3 & 4)")
    return(out)
}
avg_predictions(mod, hypothesis = fun)
```


## Comparisons and slopes

In the same ordinal logit model, we can estimate the average effect of an increase of 1 unit in `hp` on the expected probability of every level of the outcome:

```{r}
avg_comparisons(mod, variables = "hp")
```

Compare estimate for different outcome levels:

```{r}
fun <- function(x) {
    x |> 
    mutate(estimate = (estimate - lag(estimate)),
           group = sprintf("%s - %s", group, lag(group))) |>
    filter(!is.na(estimate))
}
avg_comparisons(mod, variables = "hp", hypothesis = fun)
```

Now suppose we want to compare the effect of `hp` for different levels of the outcome, but this time we do the computation  *within levels of* `cyl`:

```{r}
avg_comparisons(mod, variables = "hp", by = "cyl")
```

```{r}
fun <- function(x) {
    x |> 
    mutate(estimate = (estimate - lag(estimate)),
           group = sprintf("%s - %s", group, lag(group)), 
           .by = "cyl") |>
    filter(!is.na(estimate))
}
avg_comparisons(mod, variables = "hp", by = "cyl", hypothesis = fun)
```

````{comment}
## `specify_hypothesis()`

Supplying a function to the `hypothesis` argument is a powerful strategy, but it can sometimes be a bit tedious, because there is a lot of "boilerplate" code to write. `specify_hypothesis()` is an experimental function which handles a lot of the annoying work automatically for us: label creation, group-wise estimates, etc.

To begin, we estimate a simple model and make predictions on a grid wih 6 rows:

```{r}
dat <- transform(mtcars, gear = factor(gear))
mod <- lm(hp ~ mpg * am * factor(cyl), data = dat)

nd <- datagrid(am = 0:1, cyl = sort(unique(dat$cyl)), model = mod)

predictions(mod, newdata = nd)
```

By default, `specify_hypothesis()` computes a `reference` hypothesis, that is, the difference between each row and the first row in the output (`rowid[1]`):

```{r}
hyp <- specify_hypothesis()
predictions(mod, newdata = nd, hypothesis = hyp)
```

Alternatively, we can specify a `"sequential"` hypothesis to compare each row to its previous one:


```{r}
hyp <- specify_hypothesis(hypothesis = "sequential")
predictions(mod, newdata = nd, hypothesis = hyp)
```

A more powerful customization option is to supply one's own comparison function, along with a function to create labels. Compare each row to the global mean:

```{r}
hyp <- specify_hypothesis(
    hypothesis = \(x) x - mean(x),
    label = \(x) sprintf("%s - ȳ", x),
    label_columns = "rowid"
)
predictions(mod, newdata = nd, hypothesis = hyp)
```

The ratio of each row to the first:

```{r}
hyp <- specify_hypothesis(
    hypothesis =  \(x) x / x[1],
    label = \(x) sprintf("(%s) / (%s)", x, x[1])
)
predictions(mod, newdata = nd, hypothesis = hyp)
```

We can use the `by` argument to specify subgroups in which to apply the function. For example, we may want to compute the ratio of each row to the reference (first) row of each subgroup of `am`. Notice that the denomiator `rowid` changes depending on the `am` subgroup:

```{r}
hyp <- specify_hypothesis(
    by = "am",
    hypothesis =  \(x) x / x[1],
    label = \(x) sprintf("(%s) / (%s)", x, x[1])
)
predictions(mod, newdata = nd, hypothesis = hyp)
```

###  `term`, `contrast`, and `group`

By default, `specify_hypothesis()` will always apply comparison functions within subgroups of the `term`, `contrast`, and `group` columns. For example:

```{r}
library(MASS)
dat <- transform(mtcars, gear = factor(gear), cyl = factor(cyl))
mod <- polr(gear ~ cyl + hp, dat, Hess = TRUE)

avg_predictions(mod, by = "am")

hyp <- specify_hypothesis()
avg_predictions(mod, by = "am", hypothesis = hyp)
```

To avoid applying the function within `group` and compare group levels to one another, we can specify `by="rowid"`:

```{r}
avg_predictions(mod)

hyp <- specify_hypothesis(
    by = "rowid",
    hypothesis = "sequential",
    label_columns = "group"
)
avg_predictions(mod, hypothesis = hyp)
```

````


## Fitted models 

The `hypothesis` argument can be used to compute standard errors for arbitrary functions of model parameters. This user-supplied function must accept a single model object, and return a data.frame with two columns named `term` and `estimate`.

Here, we test if the sum of the `hp` and `mpg` coefficients is equal to 2:

```{r}
mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)

fun <- function(x) {
    b <- coef(x)
    out <- data.frame(
        term = "hp + mpg = 2",
        estimate = b["hp"] + b["mpg"] - 2,
        row.names = NULL
    )
    return(out)
}

hypotheses(mod, hypothesis = fun)
```

Test of equality between two two predictions:

```{r}
fun <- function(x) {
    p <- predict(x, newdata = mtcars)
    out <- data.frame(term = "pred[2] = pred[3]", estimate = p[2] - p[3])
    return(out)
}
hypotheses(mod, hypothesis = fun)
```

We can also use more complex aggregation patterns. In this ordinal logistic regression model, we model the number of gears for each ar. If we compute fitted values with the `predictions()` function, we obtain one predicted probability for each individual car and for each level of the response variable:

```{r}
#| messages: false
library(MASS)
library(dplyr)

dat <- transform(mtcars, 
    gear = factor(gear),
    cyl = factor(cyl))
mod <- polr(gear ~ cyl + hp, dat)

predictions(mod)
```

There are three levels to the outcome: 3, 4, and 5. Imagine that, for each car in the dataset, we want to collapse categories of the output variable into two categories ("3 & 4" and "5") by taking sums of predicted probabilities. Then, we want to take the average of those predicted probabilities for each level of `cyl`. To do so, we define a custom function, and pass it to the `hypothesis` argument of the `hypotheses()` function:

```{r}
fun <- function(x) {
    predictions(x, vcov = FALSE) |>
        # label the new categories of outcome levels
        mutate(group = ifelse(group %in% c("3", "4"), "3 & 4", "5")) |>
        # sum of probabilities at the individual level
        summarize(estimate = sum(estimate), .by = c("rowid", "cyl", "group")) |>
        # average probabilities for each value of `cyl`
        summarize(estimate = mean(estimate), .by = c("cyl", "group")) |>
        # the `FUN` argument requires a `term` column
        rename(term = cyl)
}

hypotheses(mod, hypothesis = fun)
```

Note that this workflow will not work for bayesian models or with bootstrap. However, with those models it is trivial to do the same kind of aggregation by calling `posterior_draws()` and operating directly on draws from the posterior distribution. See the vignette on bayesian analysis for examples with the `posterior_draws()` function.



# Vectors and Matrices

The `predictions()` function can estimate marginal means. The `hypothesis` argument of that function offers a powerful mechanism to estimate custom contrasts between marginal means, by way of linear combination.

## Simple contrast

Consider a simple example:

```{r}
library(marginaleffects)
library(emmeans)
library(nnet)

dat <- mtcars
dat$carb <- factor(dat$carb)
dat$cyl <- factor(dat$cyl)
dat$am <- as.logical(dat$am)
dat <- sort_by(dat, ~carb)

mod <- lm(mpg ~ carb + cyl, dat)

mm <- predictions(mod,
    by = "carb",
    newdata = "balanced")
mm
```

The contrast between marginal means for `carb==1` and `carb==2` is:

```{r}
21.66232 - 21.34058 
```

or

```{r}
21.66232 + -(21.34058)
```

or

```{r}
sum(c(21.66232, 21.34058) * c(1, -1))
```

or 

```{r}
c(21.66232, 21.34058) %*% c(1, -1)
```

The last two commands express the contrast of interest as [a linear combination](https://en.wikipedia.org/wiki/Linear_combination) of marginal means.


In the `predictions()` function, we can supply a `hypothesis` argument to compute linear combinations of marginal means. This argument must be a numeric vector of the same length as the number of rows in the output. For example, in the previous there were six rows, and the two marginal means we want to compare are at in the first two positions:

```{r}
lc <- c(1, -1, 0, 0, 0, 0)
predictions(mod,
    by = "carb",
    newdata = "balanced",
    hypothesis = lc)
```

## Complex contrast

Of course, we can also estimate more complex contrasts:

```{r}
lc <- c(0, -2, 1, 1, -1, 1)
predictions(mod,
    by = "carb",
    newdata = "balanced",
    hypothesis = lc)
```

`emmeans` produces similar results:

```{r}
library(emmeans)
em <- emmeans(mod, "carb")
lc <- data.frame(custom_contrast = c(0, -2, 1, 1, -1, 1))
contrast(em, method = lc)
```

## Multiple contrasts

Users can also compute multiple linear combinations simultaneously by supplying a numeric matrix to `hypotheses`. This matrix must have the same number of rows as the output of `slopes()`, and each column represents a distinct set of weights for different linear combinations. The column names of the matrix become labels in the output. For example:

```{r}
lc <- matrix(c(
    -2, 1, 1, 0, -1, 1,
    1, -1, 0, 0, 0, 0
    ), ncol = 2)
colnames(lc) <- c("Contrast A", "Contrast B")
lc

predictions(mod,
    by = "carb",
    newdata = "balanced",
    hypothesis = lc)
```


# Arbitrary quantities

`marginaleffects` can also compute uncertainty estimates for arbitrary quantities hosted in a data frame, as long as the user can supply a variance-covariance matrix. (Thanks to Kyle F Butts for this cool feature and example!)

Say you run a monte-carlo simulation and you want to perform hypothesis of various quantities returned from each simulation. The quantities are correlated within each draw:

```{r} 
# simulated means and medians
draw <- function(i) { 
  x <- rnorm(n = 10000, mean = 0, sd = 1)
  out <- data.frame(median = median(x), mean =  mean(x))
  return(out)
}
sims <- do.call("rbind", lapply(1:25, draw))

# average mean and average median 
coeftable <- data.frame(
  term = c("median", "mean"),
  estimate = c(mean(sims$median), mean(sims$mean))
)

# variance-covariance
vcov <- cov(sims)

# is the median equal to the mean?
hypotheses(
  coeftable,
  vcov = vcov,
  hypothesis = "median = mean"
)
```


# Joint hypotheses tests

The `hypotheses()` function can also test multiple hypotheses jointly. For example, consider this model:

```{r}
model <- lm(mpg ~ as.factor(cyl) * hp, data = mtcars)
coef(model)
```

We may want to test the null hypothesis that two of the coefficients are jointly (both) equal to zero.

```{r}
hypotheses(model, joint = c("as.factor(cyl)6:hp", "as.factor(cyl)8:hp"))
```

The `joint` argument allows users to flexibly specify the parameters to be tested, using character vectors, integer indices, or Perl-compatible regular expressions. We can also specify the null hypothesis for each parameter individually using the `hypothesis` argument.

Naturally, the `hypotheses` function also works with `marginaleffects` objects.

```{r}
# ## joint hypotheses: regular expression
hypotheses(model, joint = "cyl")

# joint hypotheses: integer indices
hypotheses(model, joint = 2:3)

# joint hypotheses: different null hypotheses
hypotheses(model, joint = 2:3, hypothesis = 1)
hypotheses(model, joint = 2:3, hypothesis = 1:2)

# joint hypotheses: marginaleffects object
cmp <- avg_comparisons(model)
hypotheses(cmp, joint = "cyl")
```

We can also combine multiple calls to `hypotheses` to execute a joint test on linear combinations of coefficients:

```{r}
# fit model
mod <- lm(mpg ~ factor(carb), mtcars)

# hypothesis matrix for linear combinations
H <- matrix(0, nrow = length(coef(mod)), ncol = 2)
H[2:3, 1] <- H[4:6, 2] <- 1

# test individual linear combinations
hyp <- hypotheses(mod, hypothesis = H)
hyp

# test joint hypotheses
#hypotheses(hyp, joint = TRUE, hypothesis = c(-10, -20))
```



# More

## Difference-in-Differences

Now we illustrate how to use the machinery described above to do pairwise comparisons between contrasts, a type of analysis often associated with a "Difference-in-Differences" research design.

First, we simulate data with two treatment groups and pre/post periods:

```{r, message = FALSE}
library(data.table)

N <- 1000
did <- data.table(
    id = 1:N,
    pre = rnorm(N),
    trt = sample(0:1, N, replace = TRUE))
did$post <- did$pre + did$trt * 0.3 + rnorm(N)
did <- melt(
    did,
    value.name = "y",
    variable.name = "time",
    id.vars = c("id", "trt"))
head(did)
```

Then, we estimate a linear model with a multiple interaction between the time and the treatment indicators. We also compute contrasts at the mean for each treatment level:

```{r}
did_model <- lm(y ~ time * trt, data = did)

comparisons(
    did_model,
    newdata = datagrid(trt = 0:1),
    variables = "time")
```

Finally, we compute pairwise differences between contrasts. This is the Diff-in-Diff estimate:

```{r}
comparisons(
    did_model,
    variables = "time",
    newdata = datagrid(trt = 0:1),
    hypothesis = "pairwise")
```

